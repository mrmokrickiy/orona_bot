import os
import logging
from aiogram import Bot, Dispatcher, types
from aiogram.utils import executor
from openai import OpenAI

# –í–∫–ª—é—á–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)

# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–∫–µ–Ω—ã –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    raise ValueError("–ù–µ –Ω–∞–π–¥–µ–Ω—ã —Ç–æ–∫–µ–Ω—ã TELEGRAM_TOKEN –∏–ª–∏ OPENAI_API_KEY!")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞ –∏ OpenAI –∫–ª–∏–µ–Ω—Ç–∞
bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher(bot)
client = OpenAI(api_key=OPENAI_API_KEY)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message_handler(commands=['start'])
async def start(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç ChatGPT ü§ñ\n–ù–∞–ø–∏—à–∏ –º–Ω–µ —á—Ç–æ-–Ω–∏–±—É–¥—å!")

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message_handler(content_types=['text'])
async def handle_message(message: types.Message):
    try:
        user_message = message.text
        await message.answer("‚è≥ –î—É–º–∞—é...")

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî —É–º–Ω—ã–π –∏ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫."},
                {"role": "user", "content": user_message}
            ],
            temperature=0.8,
            max_tokens=500
        )

        reply = response.choices[0].message.content
        await message.answer(reply)

    except Exception as e:
        logging.exception(e)
        await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
if __name__ == '__main__':
    executor.start_polling(dp, skip_updates=True)
