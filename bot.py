import os
import logging
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from openai import OpenAI

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ–∫–µ–Ω–æ–≤
TELEGRAM_TOKEN = os.getenv('TELEGRAM_TOKEN')
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')

if not TELEGRAM_TOKEN or not OPENAI_API_KEY:
    logger.error("‚ùå –¢–æ–∫–µ–Ω—ã –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã!")
    exit(1)

logger.info("‚úÖ –¢–æ–∫–µ–Ω—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher()
client = OpenAI(api_key=OPENAI_API_KEY)

@dp.message(Command("start"))
async def start_handler(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç ORONA —Å ChatGPT. –ó–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å!")

@dp.message(Command("help"))
async def help_handler(message: types.Message):
    await message.answer("–ü—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ - —è –æ—Ç–≤–µ—á—É —á–µ—Ä–µ–∑ GPT!")

@dp.message()
async def message_handler(message: types.Message):
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": message.text}],
            max_tokens=500
        )
        answer = response.choices[0].message.content
        await message.answer(answer)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞: {e}")
        await message.answer("–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞")

async def main():
    logger.info("üöÄ –ë–æ—Ç –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è...")
    await dp.start_polling(bot)

if __name__ == '__main__':
    asyncio.run(main())